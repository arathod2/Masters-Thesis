{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:42:51.149139Z",
     "iopub.status.busy": "2022-10-07T01:42:51.148749Z",
     "iopub.status.idle": "2022-10-07T01:42:51.174885Z",
     "shell.execute_reply": "2022-10-07T01:42:51.173846Z",
     "shell.execute_reply.started": "2022-10-07T01:42:51.149099Z"
    },
    "id": "63iNQCgGZFLd"
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions import kl_divergence\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# WEIGHTS ININT FUNCTION\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        try:\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            m.bias.data.fill_(0)\n",
    "        except AttributeError:\n",
    "            print(\"Skipping initialization of \", classname)\n",
    "            \n",
    "# vae module\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,  image_size, input_dim, dim, z_dim, max_capacity: int = 25, Capacity_max_iter: int = 1e5):\n",
    "        # configurations\n",
    "        super().__init__()\n",
    "        # self.label = label\n",
    "        self.z_dim = z_dim\n",
    "        self.dim = dim\n",
    "        self.input_dim = input_dim\n",
    "        self.image_size = image_size\n",
    "            \n",
    "#         encoder network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, dim, 5, 1, 0),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, z_dim * 2, 3, 1, 0),\n",
    "            nn.BatchNorm2d(z_dim * 2)\n",
    "        )\n",
    "    \n",
    "        # decoder network\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, dim, 3, 1, 0),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(dim, dim, 5, 1, 0),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(dim, dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(dim, input_dim, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode x\n",
    "        mean, logvar = self.encoder(x).chunk(2, dim=1)\n",
    "        \n",
    "        q_z_x = Normal(mean, logvar.mul(.5).exp())\n",
    "        # reconstruct x from z\n",
    "        x_reconstructed = self.decoder(q_z_x.rsample())\n",
    "\n",
    "        # return the parameters of distribution of q given x and the\n",
    "        # reconstructed image.\n",
    "        return [x_reconstructed, x, mean, logvar]\n",
    "\n",
    "    # ==============\n",
    "    # VAE components\n",
    "    # ==============\n",
    "\n",
    "    def encode(self, x):\n",
    "         # encode x\n",
    "        mean, logvar = self.encoder(x).chunk(2, dim=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "#         z = torch.reshape(z,(len(z), self.z_dim, 1, 1))\n",
    "        samples = self.decoder(z)\n",
    "        return samples\n",
    "\n",
    "    def reconstruction_loss(self, x_reconstructed, x):\n",
    "        return F.mse_loss(x_reconstructed, x, size_average=False) / x.size(0)\n",
    "\n",
    "    def kl_divergence_loss(self, mean, logvar):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + logvar - mean ** 2 - logvar.exp(), dim = (1,2,3)), dim = 0)\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # self.num_iter += 1\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        kld_weight = kwargs['M_N']\n",
    "\n",
    "        recons_loss = self.reconstruction_loss(recons,input)\n",
    "\n",
    "        kld_loss = self.kl_divergence_loss(mu, log_var)\n",
    "\n",
    "        total_loss = recons_loss + kld_weight * kld_loss\n",
    "        \n",
    "        return {'total_loss': total_loss, 'Reconstruction_Loss':recons_loss, 'KLD':kld_loss}\n",
    "\n",
    "    # =====\n",
    "    # Utils\n",
    "    # =====\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return (\n",
    "            'VAE'\n",
    "            '-{kernel_num}k'\n",
    "            '-{label}'\n",
    "            '-{channel_num}x{image_size}x{image_size}'\n",
    "        ).format(\n",
    "            label=\"\",\n",
    "            kernel_num=self.z_dim,\n",
    "            image_size=self.image_size,\n",
    "            channel_num=self.input_dim,\n",
    "        )\n",
    "\n",
    "    def sample(self, num_samples, cuda):\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.z_dim,2,2)\n",
    "\n",
    "        if cuda:\n",
    "            z = z.to('cuda')\n",
    "\n",
    "\n",
    "        samples = self.decoder(z)\n",
    "        return torch.flatten(z, start_dim=1), samples\n",
    "\n",
    "\n",
    "    def generate(self, x):\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the new image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        # encode x\n",
    "        mean, logvar = self.encoder(x).chunk(2, dim=1)\n",
    "        \n",
    "        q_z_x = Normal(mean, logvar.mul(.5).exp())\n",
    "        q_per = Normal(torch.zeros_like(mean),0.01*torch.ones_like(logvar))\n",
    "\n",
    "        # add perturbation\n",
    "        z_new = q_z_x.rsample() + q_per.rsample()\n",
    "\n",
    "        # reconstruct x from z\n",
    "        x_new = self.decoder(z_new)\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def _is_on_cuda(self):\n",
    "        return next(self.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ql0nIYBidpE"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:42:51.191989Z",
     "iopub.status.busy": "2022-10-07T01:42:51.191707Z",
     "iopub.status.idle": "2022-10-07T01:42:55.164981Z",
     "shell.execute_reply": "2022-10-07T01:42:55.163935Z",
     "shell.execute_reply.started": "2022-10-07T01:42:51.191962Z"
    },
    "id": "BQ7ukHroidpG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Dataset (train and test)\n",
    "mnist_train = pd.read_csv('./data/mnist_train.csv')\n",
    "mnist_test = pd.read_csv('./data/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:42:58.565489Z",
     "iopub.status.busy": "2022-10-07T01:42:58.565124Z",
     "iopub.status.idle": "2022-10-07T01:42:58.573525Z",
     "shell.execute_reply": "2022-10-07T01:42:58.572500Z",
     "shell.execute_reply.started": "2022-10-07T01:42:58.565452Z"
    },
    "id": "lM06VmKVidpI"
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, fashion_mnist, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.transform = transform\n",
    "       \n",
    "\n",
    "        np.random.shuffle(fashion_mnist)\n",
    "        #Get image pixels from dataset\n",
    "        self.X = fashion_mnist[:,1:]\n",
    "        \n",
    "        #Get labels\n",
    "        self.y = fashion_mnist[:,0]\n",
    "        \n",
    "#        reshape image\n",
    "        self.X  = self.X.astype(np.float64).reshape(-1, 28, 28)\n",
    "\n",
    "       \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "                Iteration function\n",
    "        \"\"\"\n",
    "        label = self.y[index]\n",
    "        image = self.X[index,:]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "#             make transformations to the image\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aTVNH43idpJ"
   },
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:42:59.469526Z",
     "iopub.status.busy": "2022-10-07T01:42:59.469147Z",
     "iopub.status.idle": "2022-10-07T01:43:00.356239Z",
     "shell.execute_reply": "2022-10-07T01:43:00.355198Z",
     "shell.execute_reply.started": "2022-10-07T01:42:59.469488Z"
    },
    "id": "_CdxpMNLidpK"
   },
   "outputs": [],
   "source": [
    "# load the trainset\n",
    "\n",
    "MNIST_train = MNISTDataset(mnist_train.values, transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "    ))\n",
    "\n",
    "# load the testset\n",
    "MNIST_test = MNISTDataset(mnist_test.values, transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:43:00.358303Z",
     "iopub.status.busy": "2022-10-07T01:43:00.357736Z",
     "iopub.status.idle": "2022-10-07T01:57:11.635193Z",
     "shell.execute_reply": "2022-10-07T01:57:11.634113Z",
     "shell.execute_reply.started": "2022-10-07T01:43:00.358266Z"
    },
    "id": "I9D3CvgLvZJX",
    "outputId": "1bc8d5fa-06e8-4a84-f598-1e0818a50a5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 1 complete! \tAverage Loss:  40.49116897583008\n"
     ]
    }
   ],
   "source": [
    "image_size = (28 , 28)\n",
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "dim = 512\n",
    "z_dim = 8\n",
    "\n",
    "# store for losses\n",
    "KLlosses, recon_losses = [],[]\n",
    "\n",
    "# Build the dataset Loader both for train and test\n",
    "train_loader = DataLoader(MNIST_train, batch_size=128, shuffle=True, \n",
    "    pin_memory=torch.cuda.is_available())\n",
    "test_loader = DataLoader(MNIST_test, batch_size=128, shuffle=True, \n",
    "    pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# check if there is GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "# inint VAE\n",
    "vae = VAE(  image_size, 1, dim, z_dim).to(device)\n",
    "\n",
    "# Init optimizer\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data,_ in train_loader:\n",
    "#         data normalization (between 0 and 1)\n",
    "        data = data/255\n",
    "    \n",
    "#     cast to float and load in GPU\n",
    "        inputs = data.to(device=device, dtype=torch.float)\n",
    "\n",
    "#     IMAGE RESHAPE\n",
    "        inputs = inputs.reshape(data.shape[0],1,28,28)\n",
    "    \n",
    "#     START TO RUN GRADIENTS\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#     Train_Step of VAE\n",
    "        x_reconstructed, x, mean, logvar = vae(inputs)\n",
    "\n",
    "    #     GET THE LOSS\n",
    "        loss = vae.loss_function(x_reconstructed, x, mean, logvar,M_N=1)\n",
    "        \n",
    "        \n",
    "        KLlosses.append(loss['KLD'])\n",
    "        recon_losses.append(loss['Reconstruction_Loss'])\n",
    "        \n",
    "        loss = loss[\"total_loss\"]\n",
    "     \n",
    "    # PERFORM BACK PROPAGATION\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l = loss.item()\n",
    "\n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKlfJZR6idpM"
   },
   "source": [
    "## Loss vs epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T02:11:32.079771Z",
     "iopub.status.busy": "2022-10-07T02:11:32.079332Z",
     "iopub.status.idle": "2022-10-07T02:11:32.483357Z",
     "shell.execute_reply": "2022-10-07T02:11:32.482392Z",
     "shell.execute_reply.started": "2022-10-07T02:11:32.079732Z"
    },
    "id": "a1Of_31MidpM"
   },
   "outputs": [],
   "source": [
    "KL_list , recon_list = [], []\n",
    "\n",
    "for l in KLlosses:\n",
    "    KL_list.append(l.cpu().detach().numpy())\n",
    "    \n",
    "for l in recon_losses:\n",
    "    recon_list.append(l.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T02:12:17.994230Z",
     "iopub.status.busy": "2022-10-07T02:12:17.993844Z",
     "iopub.status.idle": "2022-10-07T02:12:18.206302Z",
     "shell.execute_reply": "2022-10-07T02:12:18.205338Z",
     "shell.execute_reply.started": "2022-10-07T02:12:17.994197Z"
    },
    "id": "2c3M57WcidpN",
    "outputId": "78ec243f-d1c7-4c31-f7e6-205dcd127cbd"
   },
   "outputs": [],
   "source": [
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(recon_losses) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, KL_list, 'r--')\n",
    "plt.plot(epoch_count, recon_list, 'b-')\n",
    "plt.legend(['KL Loss', 'Reconstruction Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQsNzA_2idpO"
   },
   "source": [
    "## test the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:11.637262Z",
     "iopub.status.busy": "2022-10-07T01:57:11.636862Z",
     "iopub.status.idle": "2022-10-07T01:57:14.039932Z",
     "shell.execute_reply": "2022-10-07T01:57:14.038916Z",
     "shell.execute_reply.started": "2022-10-07T01:57:11.637223Z"
    },
    "id": "_Nv0Ts2SidpP",
    "outputId": "cb665676-e603-425b-b17f-befe7eea6686"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def save_generated_img(image, name, epoch, nrow=8):\n",
    "    \"\"\"\n",
    "        Save the generated image to the results directory\n",
    "    \"\"\"\n",
    "    if not os.path.exists('results_mnist'):\n",
    "        os.makedirs('results_mnist')\n",
    "\n",
    "    save_path = 'results_mnist/'+name+'_u'+str(epoch)+'.png'\n",
    "    save_image(image, save_path, nrow=nrow)\n",
    "\n",
    "vae.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "#     get bacth\n",
    "    for batch_idx, (data,_) in enumerate(tqdm.tqdm(test_loader)):\n",
    "#         load to GPU/cpu\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "\n",
    "    #     NORMALIZE DATA\n",
    "        data = data/255\n",
    "\n",
    "#         Image reshape\n",
    "        data = data.reshape(data.shape[0],1,28,28)\n",
    "        \n",
    "#         perform encoding and decoding\n",
    "        x_reconstructed, x, mean, logvar = vae(data)\n",
    "    \n",
    "#     get loss\n",
    "        loss = vae.loss_function(x_reconstructed, x, mean, logvar,M_N=1)\n",
    "        test_loss = loss[\"total_loss\"]\n",
    "\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            # saves 8 samples of the first batch as an image file to compare input images and reconstructed images\n",
    "            num_samples = min(batch_size, 8)\n",
    "            comparison = torch.cat(\n",
    "                [data[:num_samples], x_reconstructed.view(data.shape[0], 1, 28, 28)[:num_samples]]).cuda()\n",
    "            save_generated_img(\n",
    "                comparison, 'reconstruction', batch_idx, num_samples)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJo5sEhARDjO"
   },
   "source": [
    "## Generate image from noise vector\n",
    "Please note that this is not the correct generative process.\n",
    "\n",
    "Even if we don't know exact p(z|x), we can generate images from noise, since the loss function of training VAE regulates the q(z|x) (simple and tractable posteriors) must close enough to N(0, I). If q(z|x) is close to N(0, I) \"enough\"(but not tightly close due to posterior collapse problem), N(0, I) may replace the encoder of VAE.\n",
    "\n",
    "To show this, I just tested with a noise vector sampled from N(0, I) similar with Generative Adversarial Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atVVAb7PidpR"
   },
   "source": [
    "### reconstruction preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:14.042325Z",
     "iopub.status.busy": "2022-10-07T01:57:14.041461Z",
     "iopub.status.idle": "2022-10-07T01:57:14.259395Z",
     "shell.execute_reply": "2022-10-07T01:57:14.257091Z",
     "shell.execute_reply.started": "2022-10-07T01:57:14.042287Z"
    },
    "id": "9gpis7LDidpR",
    "outputId": "a896a0f6-715e-4d93-85f8-e2d73aae374d"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('./results_mnist/reconstruction_u0.png')\n",
    "\n",
    "plt.imshow(np.array(image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxOPOfObidpS"
   },
   "source": [
    "## 1. apply the r concept in the latent space of VAE, that is to calculate a norm ball distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:14.266936Z",
     "iopub.status.busy": "2022-10-07T01:57:14.264483Z",
     "iopub.status.idle": "2022-10-07T01:57:16.416026Z",
     "shell.execute_reply": "2022-10-07T01:57:16.415053Z",
     "shell.execute_reply.started": "2022-10-07T01:57:14.266905Z"
    },
    "id": "fm_cruPnidpS",
    "outputId": "67d0f06c-5802-4d5a-c42f-e37f3db6fc6b"
   },
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "labels = []\n",
    "latents = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data,label) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        #         load to GPU/cpu\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "\n",
    "        #         data normalization\n",
    "        data = data/255\n",
    "        \n",
    "        #         data reshape\n",
    "        data = data.reshape(data.shape[0],1,28,28)\n",
    "        \n",
    "#         encode data to latent space\n",
    "        mean, logvar = vae.encode(data)\n",
    "    \n",
    "#     generate samples from latent space\n",
    "        z = Normal(mean, logvar.mul(.5).exp()).rsample()\n",
    "        \n",
    "#         convert test images to latent space\n",
    "        for i in range(len(z)):\n",
    "            labels.append(label[i].cpu().detach().numpy().flatten().tolist())\n",
    "            latents.append(z[i].cpu().detach().numpy().flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgFJAiOGidpT"
   },
   "source": [
    "### calculate r-separation distance of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:16.420162Z",
     "iopub.status.busy": "2022-10-07T01:57:16.419773Z",
     "iopub.status.idle": "2022-10-07T01:57:16.429415Z",
     "shell.execute_reply": "2022-10-07T01:57:16.428310Z",
     "shell.execute_reply.started": "2022-10-07T01:57:16.420072Z"
    },
    "id": "7BY5B5ZIidpT"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "dist = np.inf\n",
    "\n",
    "# calculate r-separation distance of dataset\n",
    "def get_nearest_oppo_dist(X, y, norm, n_jobs):\n",
    "    if len(X.shape) > 2:\n",
    "        X = X.reshape(len(X), -1)\n",
    "    p = norm\n",
    "\n",
    "    def helper(yi):\n",
    "        return NearestNeighbors(n_neighbors=1, \n",
    "                                metric='minkowski', p=p, n_jobs=-1).fit(X[y != yi])\n",
    "\n",
    "    nns = Parallel(n_jobs=n_jobs)(delayed(helper)(yi) for yi in np.unique(y))\n",
    "    ret = np.zeros(len(X))\n",
    "    for yi in np.unique(y):\n",
    "        dist, _ = nns[yi].kneighbors(X[y == yi], n_neighbors=1)\n",
    "        ret[np.where(y == yi)[0]] = dist[:, 0]\n",
    "\n",
    "    return nns, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:16.431593Z",
     "iopub.status.busy": "2022-10-07T01:57:16.431178Z",
     "iopub.status.idle": "2022-10-07T01:57:16.456084Z",
     "shell.execute_reply": "2022-10-07T01:57:16.454909Z",
     "shell.execute_reply.started": "2022-10-07T01:57:16.431557Z"
    },
    "id": "bfdvUQF1idpT"
   },
   "outputs": [],
   "source": [
    "latents = np.array(latents)\n",
    "labels = np.array(labels)\n",
    "labels = np.array(labels.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y_LYiUWidpU"
   },
   "source": [
    "### r-distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:16.458170Z",
     "iopub.status.busy": "2022-10-07T01:57:16.457760Z",
     "iopub.status.idle": "2022-10-07T01:57:18.529911Z",
     "shell.execute_reply": "2022-10-07T01:57:18.528754Z",
     "shell.execute_reply.started": "2022-10-07T01:57:16.458130Z"
    },
    "id": "cFm6ct_-idpU",
    "outputId": "e62c4629-c0fe-4422-bdd8-c9d8efd167ee"
   },
   "outputs": [],
   "source": [
    "# r-distance\n",
    "nns, ret = get_nearest_oppo_dist(latents, labels, dist, -1)\n",
    "#return minimum and mean value\n",
    "print(\"2R-Separation Minimal: %f\" % ret.min())\n",
    "print(\"2R-Separation Mean: %f\" % ret.mean())\n",
    "#setting corner case corruption distance to half the separation distance\n",
    "epsilon = ret.min()/2\n",
    "print(\"Epsilon: %f\" % epsilon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsQGS3QHidpV"
   },
   "source": [
    "## 2. generate a new image from the VAE that is within the r distance of a seed input, in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T01:57:18.532339Z",
     "iopub.status.busy": "2022-10-07T01:57:18.531936Z",
     "iopub.status.idle": "2022-10-07T02:04:06.371521Z",
     "shell.execute_reply": "2022-10-07T02:04:06.370477Z",
     "shell.execute_reply.started": "2022-10-07T01:57:18.532296Z"
    },
    "id": "1Cw0zqiTidpV",
    "outputId": "0992406d-0dad-44a6-e1cd-1af39c27d998"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "r_separation = 0.564874\n",
    "test_loss = 0\n",
    "number_of_test_seeds = 1000\n",
    "\n",
    "with torch.no_grad():\n",
    "    for n_seed in range(number_of_test_seeds):\n",
    "        found = False\n",
    "        print(\"Test Seed\",n_seed+1)\n",
    "        \n",
    "        for batch_idx, (data,label) in enumerate(test_loader):\n",
    "            \n",
    "            if found:\n",
    "                break\n",
    "            \n",
    "            labels, latents = [], []\n",
    "           \n",
    "\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            data = data/255\n",
    "            data = data.reshape(data.shape[0],1,28,28)\n",
    "\n",
    "            mean, logvar = vae.encode(data)\n",
    "\n",
    "    #         make candidate samples from the latent space\n",
    "            z = Normal(mean, logvar.mul(.5).exp()).rsample()\n",
    "            \n",
    "\n",
    "            for i in range(len(z)):\n",
    "                labels.append(label[i].cpu().detach().numpy().flatten().tolist())\n",
    "                latents.append(z[i].cpu().detach().numpy().flatten().tolist())\n",
    "\n",
    "            latents = np.array(latents)\n",
    "            labels = np.array(labels)\n",
    "            labels = np.array(labels.flatten().tolist())\n",
    "\n",
    "    #         choose a seed for the latent sample\n",
    "            test_seed = latents[0]\n",
    "            \n",
    "#             rest will be candidate seeds\n",
    "            candidate_seeds = latents[1:] \n",
    "\n",
    "\n",
    "            for i in range(candidate_seeds.shape[0]):\n",
    "#                 calculate distance between test seed and candidate seed\n",
    "                dist = distance.minkowski(test_seed,candidate_seeds[i].cpu())\n",
    "    \n",
    "                if dist <= r_separation:\n",
    "                    print(\"found\")\n",
    "                    # decode candidate seed                    \n",
    "                    reconstructed = vae.decode(candidate_seeds[i].view(1, 8, 1, 1))\n",
    "                    \n",
    "                    #  decode test seed\n",
    "                    test_seed = torch.tensor(test_seed) \n",
    "                    seed_reconstruction = vae.decode(test_seed.view(1, 8, 1, 1).to(device, dtype=torch.float))\n",
    "\n",
    "                    #  combine the two to form a grid\n",
    "                    comparison = torch.cat([seed_reconstruction.view(1, 1, 28, 28), reconstructed.view(1, 1, 28, 28)]).cuda()\n",
    "                    \n",
    "                    # Save Generated Image  in the results folder\n",
    "                    # Left side  -> image from the test Image\n",
    "                    # Right side -> image from the nearest seed\n",
    "                    save_generated_img(comparison, 'reconstruction_test_seed_'+str(n_seed), batch_idx, num_samples)\n",
    "\n",
    "                    found = True\n",
    "                    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T02:04:06.373550Z",
     "iopub.status.busy": "2022-10-07T02:04:06.373171Z",
     "iopub.status.idle": "2022-10-07T02:04:06.397839Z",
     "shell.execute_reply": "2022-10-07T02:04:06.397008Z",
     "shell.execute_reply.started": "2022-10-07T02:04:06.373514Z"
    },
    "id": "44_ngGAtidpV",
    "outputId": "135034ae-e2d5-479f-ad1d-a8a4bfde8070"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"./results_mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tLf3Z3FidpW"
   },
   "source": [
    "## Image on the left is the seed while image on the right is the nearest seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T02:04:06.399894Z",
     "iopub.status.busy": "2022-10-07T02:04:06.399338Z",
     "iopub.status.idle": "2022-10-07T02:04:06.604871Z",
     "shell.execute_reply": "2022-10-07T02:04:06.603823Z",
     "shell.execute_reply.started": "2022-10-07T02:04:06.399859Z"
    },
    "id": "a5ySN5ZFidpW",
    "outputId": "76df0544-5da6-4435-dfeb-93d4f540d3a9"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('./results_mnist/reconstruction_test_seed_63_u11.png')\n",
    "\n",
    "plt.imshow(np.array(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T02:04:06.606635Z",
     "iopub.status.busy": "2022-10-07T02:04:06.606317Z",
     "iopub.status.idle": "2022-10-07T02:04:06.805405Z",
     "shell.execute_reply": "2022-10-07T02:04:06.804547Z",
     "shell.execute_reply.started": "2022-10-07T02:04:06.606608Z"
    },
    "id": "iKg1JwJdidpW",
    "outputId": "a7b80f39-bd5a-4078-aa39-59e65792beaa"
   },
   "outputs": [],
   "source": [
    "image = Image.open('./results_mnist/reconstruction_test_seed_47_u7.png')\n",
    "plt.imshow(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9vu5Z3XidpX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
